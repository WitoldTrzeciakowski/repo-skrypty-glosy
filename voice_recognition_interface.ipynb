{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Recognition Security System\n",
    "Interface for voice-based access control using ML classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import Audio, display\n",
    "from torchvision import transforms\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "import time\n",
    "from datetime import datetime\n",
    "from resample_audio_and_clear_of_noise import re_sample_audio, is_valid_wav_file\n",
    "from torchvision.models import resnet18\n",
    "from silence_removal import process_audio_file\n",
    "from create_spectrogram import process_audio_file as spectrogram_process\n",
    "from df.enhance import enhance, init_df, load_audio, save_audio\n",
    "from ipywidgets import Button, Output, HBox, VBox, Label\n",
    "\n",
    "# Constants\n",
    "LOCATORS_SPEAKERS_LIST = [\"f1\", \"f7\", \"f8\", \"m3\", \"m6\", \"m8\"]\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_PATH = 'trained_model9.pth'\n",
    "SAMPLE_RATE = 48000  # Sample rate for recording\n",
    "\n",
    "# Initialize DeepFilter for noise reduction\n",
    "model_df, df_state, _ = init_df()\n",
    "\n",
    "# Transform for spectrogram processing\n",
    "spec_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    \"\"\"Initialize and load the ResNet18 model\"\"\"\n",
    "    model = resnet18()\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(LOCATORS_SPEAKERS_LIST) + 1)\n",
    "    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Initialize the classification model\n",
    "classification_model = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_noise_for_file(audio_path, model, df_state):\n",
    "    \"\"\"Process and remove noise from a single audio file.\"\"\"\n",
    "    try:\n",
    "        if not is_valid_wav_file(audio_path):\n",
    "            print(f\"Skipping invalid WAV file: {audio_path}\")\n",
    "            return\n",
    "        \n",
    "        audio, _ = load_audio(audio_path, sr=df_state.sr())\n",
    "        enhanced = enhance(model, df_state, audio)\n",
    "        \n",
    "        enhanced_audio_path = audio_path.replace('.wav', '_enhanced.wav') \n",
    "        save_audio(enhanced_audio_path, enhanced, df_state.sr())\n",
    "        \n",
    "        print(f\"Processed: {audio_path}\")\n",
    "        return enhanced_audio_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "\n",
    "def classify_segment_from_path(spectrogram_path, model):\n",
    "    \"\"\"Classify a spectrogram image from a file path using the ResNet model.\"\"\"\n",
    "    try:\n",
    "        spec_image = Image.open(spectrogram_path).convert('RGB')\n",
    "        spec_tensor = spec_transform(spec_image).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(spec_tensor)\n",
    "            probs = torch.nn.functional.softmax(output, dim=1)\n",
    "            pred_idx = torch.argmax(probs, dim=1).item()\n",
    "            confidence = probs[0][pred_idx].item() * 100\n",
    "        \n",
    "        return pred_idx, confidence\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during classification: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    \"\"\"Process an audio file through the complete pipeline: enhance, split, and classify.\"\"\"\n",
    "    try:\n",
    "        print(\"Starting audio processing...\")\n",
    "        \n",
    "        # Resample the audio\n",
    "        print(\"Resampling audio...\")\n",
    "        resampled_path = re_sample_audio(file_path)\n",
    "        \n",
    "        # Remove noise\n",
    "        print(\"Removing noise...\")\n",
    "        enhanced_path = delete_noise_for_file(resampled_path, model_df, df_state)\n",
    "        \n",
    "        # Split into segments\n",
    "        print(\"Splitting into segments...\")\n",
    "        audio_paths = process_audio_file(enhanced_path)\n",
    "        \n",
    "        # Process each segment\n",
    "        authorized_count = 0\n",
    "        total_segments = 0\n",
    "        \n",
    "        print(\"\\nAnalyzing segments:\")\n",
    "        for audio_path in audio_paths:\n",
    "            spectrogram_path = spectrogram_process(audio_path, \"temp\")\n",
    "            predicted_class, confidence = classify_segment_from_path(spectrogram_path, classification_model)\n",
    "            \n",
    "            if predicted_class is not None:\n",
    "                total_segments += 1\n",
    "                speaker = LOCATORS_SPEAKERS_LIST[predicted_class] if predicted_class < 6 else \"Unauthorized\"\n",
    "                print(f\"Segment {total_segments}: {speaker} (Confidence: {confidence:.2f}%)\")\n",
    "                \n",
    "                if predicted_class < 6:\n",
    "                    authorized_count += 1\n",
    "        \n",
    "        # Make final decision\n",
    "        if total_segments > 0:\n",
    "            print(\"\\nAccess Decision:\")\n",
    "            if authorized_count > total_segments / 2:\n",
    "                print(\"✅ ACCESS GRANTED\")\n",
    "            else:\n",
    "                print(\"❌ ACCESS DENIED\")\n",
    "            print(f\"Authorized segments: {authorized_count}/{total_segments}\")\n",
    "            \n",
    "            # Play the original audio\n",
    "            display(Audio(file_path))\n",
    "        else:\n",
    "            print(\"No valid segments found for analysis\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in processing: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_button = Button(description='Upload and Process WAV File')\n",
    "record_button = Button(description='Record Audio')\n",
    "stop_button = Button(description='Stop Recording')\n",
    "stop_button.disabled = True\n",
    "status_label = Label(value='Ready to record or upload file')\n",
    "output = Output()\n",
    "\n",
    "# Recording variables\n",
    "recording = False\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"Record audio from the microphone\"\"\"\n",
    "    global recording\n",
    "    recording = True\n",
    "    \n",
    "    # Generate unique filename based on timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f'recording_{timestamp}.wav'\n",
    "    \n",
    "    # Update UI\n",
    "    record_button.disabled = True\n",
    "    stop_button.disabled = False\n",
    "    status_label.value = 'Recording... Press Stop when done'\n",
    "    \n",
    "    # Start recording\n",
    "    audio_data = []\n",
    "    \n",
    "    def callback(indata, frames, time, status):\n",
    "        if recording:\n",
    "            audio_data.append(indata.copy())\n",
    "    \n",
    "    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, callback=callback):\n",
    "        while recording:\n",
    "            time.sleep(0.1)\n",
    "    \n",
    "    # Combine all audio chunks and save\n",
    "    if audio_data:\n",
    "        audio = np.concatenate(audio_data)\n",
    "        wav.write(filename, SAMPLE_RATE, audio)\n",
    "        print(f\"Recording saved as {filename}\")\n",
    "        process_file(filename)\n",
    "    \n",
    "    # Reset UI\n",
    "    record_button.disabled = False\n",
    "    stop_button.disabled = True\n",
    "\n",
    "def stop_recording(b):\n",
    "    \"\"\"Stop the current recording\"\"\"\n",
    "    global recording\n",
    "    recording = False\n",
    "    \n",
    "def start_recording(b):\n",
    "    \"\"\"Start a new recording in a separate thread\"\"\"\n",
    "    import threading\n",
    "    thread = threading.Thread(target=record_audio)\n",
    "    thread.start()\n",
    "\n",
    "def on_button_click(b):\n",
    "    \"\"\"Handle file upload button click\"\"\"\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title='Select WAV File',\n",
    "            filetypes=[('WAV files', '*.wav')]\n",
    "        )\n",
    "        if file_path:\n",
    "            process_file(file_path)\n",
    "\n",
    "# Connect button handlers\n",
    "upload_button.on_click(on_button_click)\n",
    "record_button.on_click(start_recording)\n",
    "stop_button.on_click(stop_recording)\n",
    "\n",
    "# Create layout\n",
    "buttons = HBox([upload_button, record_button, stop_button])\n",
    "controls = VBox([buttons, status_label])\n",
    "display(controls, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
