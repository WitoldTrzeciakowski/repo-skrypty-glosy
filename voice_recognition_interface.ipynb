{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Recognition Security System\n",
    "Interface for voice-based access control using ML classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from df.enhance import init_df, enhance\n",
    "from resample_audio_and_clear_of_noise import re_sample_audio, is_valid_wav_file\n",
    "from create_spectogram import save_spectrogram\n",
    "from silence_removal import process_audio_file\n",
    "\n",
    "# Initialize models\n",
    "model_df, df_state, _ = init_df()\n",
    "\n",
    "# Load classification model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, 20)\n",
    "model.load_state_dict(torch.load('trained_model3.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "   \"\"\"Process audio file and verify identity\"\"\"\n",
    "   try:\n",
    "       if not is_valid_wav_file(file_path):\n",
    "           print(\"Invalid WAV file\")\n",
    "           return\n",
    "\n",
    "       # Resample audio to 48kHz\n",
    "       re_sample_audio(file_path)\n",
    "       \n",
    "       # Get audio segments using silence removal function\n",
    "       audio, sr = librosa.load(file_path, sr=48000)\n",
    "       audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)\n",
    "       enhanced = enhance(model_df, df_state, audio_tensor)\n",
    "       enhanced_numpy = enhanced.squeeze(0).cpu().numpy()\n",
    "       \n",
    "       segments = librosa.effects.split(enhanced_numpy, top_db=60)\n",
    "       print(f\"Found {len(segments)} segments\")\n",
    "       \n",
    "       authorized_count = 0\n",
    "       total_confidence = 0\n",
    "       processed_segments = 0  # Counter for processed segments\n",
    "       \n",
    "       for i, (start, end) in enumerate(segments):\n",
    "           segment = enhanced_numpy[start:end]\n",
    "           if len(segment) / sr < 4:  # Skip segments shorter than 4 seconds\n",
    "               continue\n",
    "               \n",
    "           try:\n",
    "               # Generate spectrogram data\n",
    "               spec = librosa.stft(segment)\n",
    "               spec_db = librosa.amplitude_to_db(abs(spec))\n",
    "               \n",
    "               # Normalize and prepare for model\n",
    "               spec_norm = (spec_db - spec_db.min()) / (spec_db.max() - spec_db.min())\n",
    "               spec_tensor = torch.FloatTensor(spec_norm).unsqueeze(0).repeat(3, 1, 1)\n",
    "               spec_tensor = spec_tensor.unsqueeze(0)\n",
    "               spec_tensor = spec_tensor.to(device)\n",
    "               \n",
    "               with torch.no_grad():\n",
    "                   output = model(spec_tensor)\n",
    "                   probs = torch.nn.functional.softmax(output, dim=1)\n",
    "                   pred_idx = torch.argmax(output).item()\n",
    "                   confidence = probs[0][pred_idx].item() * 100\n",
    "                   \n",
    "                   is_authorized = pred_idx in [0, 1, 2, 3, 4, 5]\n",
    "                   if is_authorized:\n",
    "                       authorized_count += 1\n",
    "                   total_confidence += confidence\n",
    "                   processed_segments += 1  # Increment counter only for successfully processed segments\n",
    "                   \n",
    "                   print(f\"Segment {i+1}: {'Authorized' if is_authorized else 'Unauthorized'} \"\n",
    "                         f\"(Confidence: {confidence:.2f}%)\")\n",
    "                   \n",
    "           except Exception as e:\n",
    "               print(f\"Error processing segment {i+1}: {str(e)}\")\n",
    "               continue\n",
    "       \n",
    "       if processed_segments > 0:  # Check if any segments were processed\n",
    "           final_authorized = authorized_count > processed_segments / 2\n",
    "           avg_confidence = total_confidence / processed_segments  # Calculate average using processed segments\n",
    "           \n",
    "           print(\"\\nAccess Decision:\")\n",
    "           print(\"✅ ACCESS GRANTED\" if final_authorized else \"❌ ACCESS DENIED\")\n",
    "           print(f\"Average Confidence: {avg_confidence:.2f}%\")\n",
    "           print(f\"Authorized segments: {authorized_count}/{processed_segments}\")\n",
    "           print(f\"Processed {processed_segments} out of {len(segments)} total segments\")\n",
    "           \n",
    "           display(Audio(file_path))\n",
    "           \n",
    "   except Exception as e:\n",
    "       print(f\"Error processing file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Button, Output\n",
    "\n",
    "output = Output()\n",
    "button = Button(description='Upload and Process WAV File')\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title='Select WAV File',\n",
    "            filetypes=[('WAV files', '*.wav')]\n",
    "        )\n",
    "        if file_path:\n",
    "            process_file(file_path)\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "display(button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
